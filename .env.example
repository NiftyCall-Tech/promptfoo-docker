# =============================================================================
# Promptfoo Docker – environment template
# =============================================================================
# 1. Copy this file:  cp .env.example .env
# 2. Fill in the API keys you need (leave others empty or remove the line).
# 3. Do not commit .env – it is for secrets.
#
# Full list of providers and their env vars:
#   https://www.promptfoo.dev/docs/providers/
# =============================================================================

# -----------------------------------------------------------------------------
# Common LLM provider API keys (set only the ones you use)
# -----------------------------------------------------------------------------
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=
AZURE_OPENAI_API_KEY=
OPENROUTER_API_KEY=
DEEPSEEK_API_KEY=
MISTRAL_API_KEY=
GROQ_API_KEY=
COHERE_API_KEY=
HUGGINGFACE_HUB_API_KEY=
PERPLEXITY_API_KEY=
REPLICATE_API_TOKEN=
XAI_API_KEY=

# Optional: more providers (see https://www.promptfoo.dev/docs/providers/)
# FIREWORKS_API_KEY=
# CEREBRAS_API_KEY=
# AI21_API_KEY=
# VOYAGE_API_KEY=
# CLOUDFLARE_API_TOKEN=   # Cloudflare Workers AI
# TOGETHER_API_KEY=
# For AWS Bedrock: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION

# -----------------------------------------------------------------------------
# Promptfoo self-hosted / server options
# -----------------------------------------------------------------------------
# Chunk size for sharing large evals (default 10). Increase for big outputs.
PROMPTFOO_SHARE_CHUNK_SIZE=10

# If using the CLI to push results to this server, set on the *client* machine:
# PROMPTFOO_REMOTE_API_BASE_URL=http://localhost:3000
# PROMPTFOO_REMOTE_APP_BASE_URL=http://localhost:3000

# -----------------------------------------------------------------------------
# Optional: proxy (e.g. corporate network)
# -----------------------------------------------------------------------------
# HTTP_PROXY=
# HTTPS_PROXY=
# NO_PROXY=
